# SCIN Data Pipeline: Download + Cleaning

**INSY 674 Group Project**

## Project Overview

This project currently focuses on building a reliable base data pipeline for the SCIN (Skin Condition Image Network) dataset:
- Download raw SCIN metadata and images
- Merge and clean case + label data
- Produce a cleaned modeling-ready table for downstream work

This repository does **not** currently include EDA, feature engineering, model training, or performance evaluation as part of the primary workflow.

## Objectives

The current objective is data quality and reproducible preprocessing:
- Standardized ingestion from the SCIN public bucket
- Consistent cleaned dataset generation
- Clear label handling for downstream multi-label experiments

## Dataset

The SCIN dataset contains dermatological cases with comprehensive clinical information:

### Files
- `dataset_scin_cases.csv` - Patient demographics, symptoms, affected body parts, and clinical metadata (5,033 cases, 57 features)
- `dataset_scin_labels.csv` - Dermatologist-assigned diagnoses, confidence scores, and skin type assessments (5,033 cases, 17 features)

### Key Features
**Demographics:**
- Age groups, sex at birth
- Fitzpatrick skin types (self-reported and dermatologist-assessed)
- Monk skin tone scales (India and US)
- Race and ethnicity information

**Clinical Characteristics:**
- Skin texture (raised/bumpy, flat, rough/flaky, fluid-filled)
- Affected body parts (head/neck, arms, legs, torso, etc.)
- Condition symptoms (itching, pain, bleeding, darkening, etc.)
- Other systemic symptoms (fever, fatigue, joint pain, etc.)
- Condition duration and category

**Target Variables:**
- Weighted skin condition labels (dermatologist consensus)
- Skin condition confidence scores
- Image gradability assessments

## Current Workflow

### 1) Download
- Download SCIN CSV files (`scin_cases.csv`, `scin_labels.csv`, etc.)
- Optionally download all images

### 2) Preprocess (Cleaning)
- Merge `scin_cases.csv` and `scin_labels.csv` on `case_id`
- Parse `dermatologist_skin_condition_on_label_name`
- Drop rows without usable labels or without image paths
- Build:
  - `image_paths` (JSON list)
  - `num_images`
  - `label_all` (deduplicated full condition list)
  - `label` (first 3 labels, JSON list)
- Save cleaned output to `data/processed/cleaned.csv`
- Optional: create `train.csv` / `test.csv` split

## Repository Structure

```
Scin-Data-Modeling/
├── README.md
├── model.ipynb              # Notebook sandbox (not part of base pipeline)
├── data/
│   ├── raw/
│   │   └── dataset/
│   │       ├── scin_cases.csv
│   │       ├── scin_labels.csv
│   │       └── images/
│   └── processed/
│       ├── cleaned.csv
│       ├── train.csv        # optional
│       └── test.csv         # optional
└── scin_data_modeling/
    ├── cli.py
    └── data/
        ├── download.py
        └── preprocess.py
```

## Technical Requirements

### Python Libraries
- `pandas`, `numpy`
- `google-cloud-storage`, `tqdm`
- `typer`, `rich`
- `scikit-learn` (only for optional train/test split utility)

### Installation
```bash
pip install -e .
```

## Usage

### Run base pipeline (download + cleaning)

```bash
scin_data_modeling pipeline --no-images
```

### Run without downloading images (metadata-only)

Use this mode when you want CSV ingestion + cleaning only and do not want to download image files.

```bash
scin_data_modeling pipeline --no-images
```

You can also run step-by-step:

```bash
scin_data_modeling download --no-images
scin_data_modeling preprocess --no-create-split
```

### Run steps individually

```bash
scin_data_modeling download --no-images
scin_data_modeling preprocess --no-create-split
```

### Optional split creation

```bash
scin_data_modeling preprocess --create-split --test-size 0.2 --seed 42
```

### Optional image embeddings during preprocessing (ResNet)

If you want CNN image embeddings as part of preprocessing, enable embedding creation.
The default backbone is `resnet50`.

```bash
scin_data_modeling preprocess \
  --create-embeddings \
  --embedding-backbone resnet50 \
  --embedding-device cpu
```

You can run the same flow through the pipeline command:

```bash
scin_data_modeling pipeline --no-images --create-embeddings --embedding-backbone resnet50
```

Embeddings are generated by streaming images directly from the SCIN GCS bucket; local image files are not required.

### Output

- Primary artifact: `data/processed/cleaned.csv`
- Optional artifacts: `data/processed/train.csv`, `data/processed/test.csv`
- Optional embedding artifacts: `data/processed/embeddings_train.npz`, `data/processed/embeddings_test.npz`

## Notes on Labels

- Raw target source: `dermatologist_skin_condition_on_label_name` in `scin_labels.csv`
- Cleaned `label_all`: deduplicated full list of condition names per case
- Cleaned `label`: first 3 items from `label_all` for downstream top-3 prediction workflows

## Contributors

INSY 674 Group Project Team

## License

This project is for educational purposes as part of INSY 674 coursework.

## Acknowledgments

- SCIN (Skin Condition Image Network) dataset providers
- Course instructors and teaching assistants

---

*Last Updated: February 2026*
